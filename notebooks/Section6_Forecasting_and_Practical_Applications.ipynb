{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Forecasting and Practical Applications\n",
    "\n",
    "#### PyData London 2025 - Bayesian Time Series Analysis with PyMC\n",
    "\n",
    "---\n",
    "\n",
    "## The Power of Probabilistic Forecasting\n",
    "\n",
    "Traditional forecasting methods provide point estimates with confidence intervals based on strong assumptions. **Bayesian forecasting** offers several advantages:\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **Full Uncertainty Quantification**: Complete probability distributions over future values\n",
    "2. **Coherent Uncertainty Propagation**: Parameter uncertainty flows naturally into forecasts\n",
    "3. **Flexible Prediction Intervals**: Any quantile or probability can be computed\n",
    "4. **Decision-Theoretic Framework**: Optimal decisions under uncertainty\n",
    "\n",
    "### Forecast Types\n",
    "\n",
    "- **Point forecasts**: Expected values (posterior means)\n",
    "- **Interval forecasts**: Credible intervals (e.g., 90% HDI)\n",
    "- **Probabilistic forecasts**: Full predictive distributions\n",
    "- **Scenario analysis**: Probability of specific events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Section 6\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import warnings\n",
    "\n",
    "# Configure plotting and suppress warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"ðŸ”§ Section 6 libraries loaded successfully!\")\n",
    "print(\"Ready to generate probabilistic forecasts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Train-Test Split\n",
    "\n",
    "For proper forecast evaluation, we need to split our data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data with train-test split\n",
    "births_data = pl.read_csv('../data/births.csv', null_values=['null', 'NA', '', 'NULL'])\n",
    "births_data = births_data.filter(pl.col('day').is_not_null())\n",
    "\n",
    "monthly_births = (births_data\n",
    "    .group_by(['year', 'month'])\n",
    "    .agg(pl.col('births').sum())\n",
    "    .sort(['year', 'month'])\n",
    ")\n",
    "\n",
    "births_subset = (monthly_births\n",
    "    .filter((pl.col('year') >= 1970) & (pl.col('year') <= 1990))\n",
    "    .with_row_index('index')\n",
    ")\n",
    "\n",
    "# Standardize the data\n",
    "original_data = births_subset['births'].to_numpy()\n",
    "births_standardized = (original_data - original_data.mean()) / original_data.std()\n",
    "\n",
    "# Train-test split (use last 24 months for testing)\n",
    "n_forecast = 24\n",
    "n_train = len(births_standardized) - n_forecast\n",
    "\n",
    "y_train = births_standardized[:n_train]\n",
    "y_test = births_standardized[n_train:]\n",
    "\n",
    "print(f\"ðŸ“Š Data split:\")\n",
    "print(f\"   Training: {len(y_train)} observations\")\n",
    "print(f\"   Testing: {len(y_test)} observations\")\n",
    "print(f\"   Forecast horizon: {n_forecast} months\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Forecasting Model\n",
    "\n",
    "Let's build a seasonal model that can generate forecasts with uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a seasonal model for forecasting\n",
    "time_idx_train = np.arange(len(y_train))\n",
    "time_normalized_train = (time_idx_train - time_idx_train.mean()) / time_idx_train.std()\n",
    "\n",
    "# Create seasonal components for training data\n",
    "period = 12  # Monthly data with annual seasonality\n",
    "seasonal_freq = 2 * np.pi / period\n",
    "sin_seasonal_train = np.sin(seasonal_freq * time_idx_train)\n",
    "cos_seasonal_train = np.cos(seasonal_freq * time_idx_train)\n",
    "\n",
    "with pm.Model() as forecast_model:\n",
    "    # Model parameters\n",
    "    mu_overall = pm.Normal('mu_overall', mu=0, sigma=1)\n",
    "    beta_trend = pm.Normal('beta_trend', mu=0, sigma=1)\n",
    "    beta_sin = pm.Normal('beta_sin', mu=0, sigma=1)\n",
    "    beta_cos = pm.Normal('beta_cos', mu=0, sigma=1)\n",
    "    \n",
    "    # Expected value for training data\n",
    "    mu_train = pm.Deterministic('mu_train', \n",
    "                               mu_overall + \n",
    "                               beta_trend * time_normalized_train + \n",
    "                               beta_sin * sin_seasonal_train + \n",
    "                               beta_cos * cos_seasonal_train)\n",
    "    \n",
    "    # Observation noise\n",
    "    sigma_obs = pm.HalfNormal('sigma_obs', sigma=1)\n",
    "    \n",
    "    # Likelihood (training data only)\n",
    "    y_obs = pm.Normal('y_obs', mu=mu_train, sigma=sigma_obs, observed=y_train)\n",
    "\n",
    "# Fit the model\n",
    "with forecast_model:\n",
    "    trace_forecast = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "print(\"âœ… Forecasting model fitted successfully\")\n",
    "print(az.summary(trace_forecast, var_names=['mu_overall', 'beta_trend', 'beta_sin', 'beta_cos', 'sigma_obs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Probabilistic Forecasts\n",
    "\n",
    "Now let's generate forecasts for the test period with full uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts for the test period\n",
    "time_idx_forecast = np.arange(len(y_train), len(y_train) + n_forecast)\n",
    "time_normalized_forecast = (time_idx_forecast - time_idx_train.mean()) / time_idx_train.std()\n",
    "\n",
    "# Create seasonal components for forecast period\n",
    "sin_seasonal_forecast = np.sin(seasonal_freq * time_idx_forecast)\n",
    "cos_seasonal_forecast = np.cos(seasonal_freq * time_idx_forecast)\n",
    "\n",
    "# Generate forecasts using posterior samples\n",
    "with forecast_model:\n",
    "    # Compute expected values for forecast period\n",
    "    mu_forecast = pm.Deterministic('mu_forecast',\n",
    "                                  trace_forecast.posterior['mu_overall'] +\n",
    "                                  trace_forecast.posterior['beta_trend'] * time_normalized_forecast +\n",
    "                                  trace_forecast.posterior['beta_sin'] * sin_seasonal_forecast +\n",
    "                                  trace_forecast.posterior['beta_cos'] * cos_seasonal_forecast)\n",
    "    \n",
    "    # Generate predictive samples\n",
    "    y_forecast = pm.Normal('y_forecast', \n",
    "                          mu=mu_forecast, \n",
    "                          sigma=trace_forecast.posterior['sigma_obs'])\n",
    "    \n",
    "    # Sample from posterior predictive distribution\n",
    "    forecast_samples = pm.sample_posterior_predictive(trace_forecast, \n",
    "                                                     var_names=['y_forecast'],\n",
    "                                                     random_seed=RANDOM_SEED)\n",
    "\n",
    "print(\"ðŸ”® Generated probabilistic forecasts for test period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract forecast statistics\n",
    "forecast_data = forecast_samples.posterior_predictive['y_forecast']\n",
    "\n",
    "# Compute forecast statistics\n",
    "forecast_mean = forecast_data.mean(dim=['chain', 'draw'])\n",
    "forecast_median = forecast_data.median(dim=['chain', 'draw'])\n",
    "forecast_hdi_90 = az.hdi(forecast_data, hdi_prob=0.9)\n",
    "forecast_hdi_50 = az.hdi(forecast_data, hdi_prob=0.5)\n",
    "\n",
    "print(\"ðŸ“Š Forecast Statistics Computed:\")\n",
    "print(f\"   Mean forecast: {forecast_mean.values[:5]} ... (first 5 values)\")\n",
    "print(f\"   90% HDI width: {(forecast_hdi_90.sel(hdi='higher') - forecast_hdi_90.sel(hdi='lower')).values[:5]} ... (first 5 values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Visualization and Evaluation\n",
    "\n",
    "Let's visualize our forecasts and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive forecast visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Full time series with forecasts\n",
    "time_all = np.arange(len(births_standardized))\n",
    "time_train = time_all[:n_train]\n",
    "time_test = time_all[n_train:]\n",
    "\n",
    "# Plot training data\n",
    "ax1.plot(time_train, y_train, 'o-', color='blue', alpha=0.7, label='Training Data')\n",
    "\n",
    "# Plot test data (actual)\n",
    "ax1.plot(time_test, y_test, 'o-', color='red', alpha=0.7, label='Actual (Test)')\n",
    "\n",
    "# Plot forecasts\n",
    "ax1.plot(time_test, forecast_mean, 's-', color='green', linewidth=2, label='Forecast Mean')\n",
    "\n",
    "# Plot uncertainty bands\n",
    "ax1.fill_between(time_test, \n",
    "                forecast_hdi_90.sel(hdi='lower'), \n",
    "                forecast_hdi_90.sel(hdi='higher'), \n",
    "                alpha=0.3, color='green', label='90% HDI')\n",
    "\n",
    "ax1.fill_between(time_test, \n",
    "                forecast_hdi_50.sel(hdi='lower'), \n",
    "                forecast_hdi_50.sel(hdi='higher'), \n",
    "                alpha=0.5, color='green', label='50% HDI')\n",
    "\n",
    "ax1.axvline(n_train, color='black', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
    "ax1.set_title('Bayesian Time Series Forecasting with Uncertainty')\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Standardized Births')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Forecast errors\n",
    "forecast_errors = y_test - forecast_mean.values\n",
    "ax2.plot(time_test, forecast_errors, 'o-', color='purple', alpha=0.7)\n",
    "ax2.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "ax2.set_title('Forecast Errors')\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Error (Actual - Forecast)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute forecast evaluation metrics\n",
    "mae = np.mean(np.abs(forecast_errors))\n",
    "rmse = np.sqrt(np.mean(forecast_errors**2))\n",
    "mape = np.mean(np.abs(forecast_errors / y_test)) * 100\n",
    "\n",
    "print(f\"\\nðŸ“ˆ **Forecast Evaluation Metrics**:\")\n",
    "print(f\"   Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"   Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"   Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Coverage analysis\n",
    "in_90_hdi = ((y_test >= forecast_hdi_90.sel(hdi='lower').values) & \n",
    "             (y_test <= forecast_hdi_90.sel(hdi='higher').values))\n",
    "coverage_90 = np.mean(in_90_hdi) * 100\n",
    "\n",
    "in_50_hdi = ((y_test >= forecast_hdi_50.sel(hdi='lower').values) & \n",
    "             (y_test <= forecast_hdi_50.sel(hdi='higher').values))\n",
    "coverage_50 = np.mean(in_50_hdi) * 100\n",
    "\n",
    "print(f\"\\nðŸŽ¯ **Coverage Analysis**:\")\n",
    "print(f\"   90% HDI Coverage: {coverage_90:.1f}% (target: 90%)\")\n",
    "print(f\"   50% HDI Coverage: {coverage_50:.1f}% (target: 50%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Applications and Decision Making\n",
    "\n",
    "Bayesian forecasts enable sophisticated decision-making under uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practical applications: Probabilistic decision making\n",
    "print(\"ðŸŽ¯ **Practical Applications: Decision Making Under Uncertainty**\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Example 1: Probability of exceeding thresholds\n",
    "threshold_high = 1.0  # High birth count threshold\n",
    "threshold_low = -1.0  # Low birth count threshold\n",
    "\n",
    "prob_exceed_high = (forecast_data > threshold_high).mean(dim=['chain', 'draw'])\n",
    "prob_below_low = (forecast_data < threshold_low).mean(dim=['chain', 'draw'])\n",
    "\n",
    "print(f\"\\n**Threshold Analysis**:\")\n",
    "print(f\"   Probability of exceeding {threshold_high}: {prob_exceed_high.values[:6]} (first 6 months)\")\n",
    "print(f\"   Probability of falling below {threshold_low}: {prob_below_low.values[:6]} (first 6 months)\")\n",
    "\n",
    "# Example 2: Risk assessment\n",
    "risk_months = np.where(prob_exceed_high > 0.7)[0]\n",
    "if len(risk_months) > 0:\n",
    "    print(f\"\\n**Risk Assessment**:\")\n",
    "    print(f\"   High-risk months (>70% chance of exceeding threshold): {risk_months + 1}\")\n",
    "else:\n",
    "    print(f\"\\n**Risk Assessment**: No high-risk months identified\")\n",
    "\n",
    "# Example 3: Quantile forecasts for planning\n",
    "quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "forecast_quantiles = forecast_data.quantile(quantiles, dim=['chain', 'draw'])\n",
    "\n",
    "print(f\"\\n**Quantile Forecasts for Planning** (first 3 months):\")\n",
    "for i, q in enumerate(quantiles):\n",
    "    values = forecast_quantiles.isel(quantile=i).values[:3]\n",
    "    print(f\"   {q*100:4.0f}th percentile: {values}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ **Business Applications**:\")\n",
    "print(f\"   â€¢ **Capacity Planning**: Use 90th percentile for resource allocation\")\n",
    "print(f\"   â€¢ **Risk Management**: Monitor probabilities of extreme events\")\n",
    "print(f\"   â€¢ **Inventory Management**: Optimize stock levels using full distribution\")\n",
    "print(f\"   â€¢ **Financial Planning**: Budget based on uncertainty ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices for Bayesian Forecasting\n",
    "\n",
    "### Model Selection and Validation\n",
    "1. **Use proper scoring rules** (e.g., CRPS) for probabilistic forecast evaluation\n",
    "2. **Implement rolling window validation** for robust performance assessment\n",
    "3. **Check forecast calibration** - do 90% intervals contain 90% of observations?\n",
    "4. **Monitor model performance** over time and retrain when necessary\n",
    "\n",
    "### Communication and Interpretation\n",
    "1. **Visualize uncertainty clearly** using fan charts or probability bands\n",
    "2. **Provide multiple scenarios** (optimistic, realistic, pessimistic)\n",
    "3. **Explain probabilistic language** to non-technical stakeholders\n",
    "4. **Focus on decision-relevant metrics** rather than just point forecasts\n",
    "\n",
    "### Technical Considerations\n",
    "1. **Account for model uncertainty** through model averaging\n",
    "2. **Handle structural breaks** with time-varying parameters\n",
    "3. **Incorporate external information** through informative priors\n",
    "4. **Scale computations** for high-frequency or multivariate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this tutorial, we've covered:\n",
    "\n",
    "1. **Section 1**: Motivation and time series fundamentals\n",
    "2. **Section 2**: Bayesian inference and PyMC workflow\n",
    "3. **Section 3**: Basic time series models (random walks, AR models)\n",
    "4. **Section 4**: Advanced models (state-space, stochastic volatility, GPs)\n",
    "5. **Section 5**: Model diagnostics and comparison\n",
    "6. **Section 6**: Probabilistic forecasting and applications\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Bayesian methods provide natural uncertainty quantification** for time series\n",
    "- **PyMC offers powerful tools** for building sophisticated time series models\n",
    "- **Proper diagnostics are essential** for reliable inference\n",
    "- **Probabilistic forecasts enable better decision-making** under uncertainty\n",
    "\n",
    "### Further Learning\n",
    "\n",
    "- **Advanced Topics**: Vector autoregressions, dynamic factor models, regime-switching models\n",
    "- **Computational Methods**: Variational inference, particle filters, sequential Monte Carlo\n",
    "- **Applications**: Finance, epidemiology, climate science, marketing mix modeling\n",
    "- **Software**: Stan, TensorFlow Probability, Pyro for alternative implementations\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for joining this tutorial on Bayesian Time Series Analysis with PyMC!**\n",
    "\n",
    "**Questions? Let's discuss!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
