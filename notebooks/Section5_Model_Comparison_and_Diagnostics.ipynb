{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Model Comparison and Diagnostics\n",
    "\n",
    "#### PyData London 2025 - Bayesian Time Series Analysis with PyMC\n",
    "\n",
    "---\n",
    "\n",
    "## Why Model Diagnostics Matter\n",
    "\n",
    "Model diagnostics are crucial for ensuring that:\n",
    "- **MCMC chains have converged** to the target distribution\n",
    "- **Models fit the data appropriately** without systematic biases\n",
    "- **Model assumptions are reasonable** for the given data\n",
    "- **Model selection is based on sound criteria** rather than just fit\n",
    "\n",
    "### The Bayesian Workflow\n",
    "\n",
    "1. **Build model** ‚Üí 2. **Check convergence** ‚Üí 3. **Validate fit** ‚Üí 4. **Compare models** ‚Üí 5. **Iterate**\n",
    "\n",
    "This iterative process ensures robust, reliable models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Section 5\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import warnings\n",
    "from scipy import stats\n",
    "\n",
    "# Configure plotting and suppress warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"üîß Section 5 libraries loaded successfully!\")\n",
    "print(\"Ready to diagnose and compare Bayesian time series models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and build several models for comparison\n",
    "births_data = pl.read_csv('../data/births.csv', null_values=['null', 'NA', '', 'NULL'])\n",
    "births_data = births_data.filter(pl.col('day').is_not_null())\n",
    "\n",
    "monthly_births = (births_data\n",
    "    .group_by(['year', 'month'])\n",
    "    .agg(pl.col('births').sum())\n",
    "    .sort(['year', 'month'])\n",
    ")\n",
    "\n",
    "births_subset = (monthly_births\n",
    "    .filter((pl.col('year') >= 1970) & (pl.col('year') <= 1990))\n",
    "    .with_row_index('index')\n",
    ")\n",
    "\n",
    "original_data = births_subset['births'].to_numpy()\n",
    "births_standardized = (original_data - original_data.mean()) / original_data.std()\n",
    "n_obs = len(births_standardized)\n",
    "\n",
    "print(f\"üìä Data prepared: {n_obs} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models for Comparison\n",
    "\n",
    "Let's build several models that we can compare and diagnose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Simple Normal Model (baseline)\n",
    "with pm.Model() as normal_model:\n",
    "    mu = pm.Normal('mu', mu=0, sigma=1)\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "    obs = pm.Normal('obs', mu=mu, sigma=sigma, observed=births_standardized)\n",
    "    trace_normal = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "# Model 2: AR(1) Model\n",
    "with pm.Model() as ar1_model:\n",
    "    rho = pm.Beta('rho', alpha=1, beta=1)\n",
    "    phi = pm.Deterministic('phi', 2 * rho - 1)\n",
    "    sigma = pm.HalfNormal('sigma', sigma=1)\n",
    "    ar1 = pm.AR('ar1', rho=phi, sigma=sigma, constant=False, steps=n_obs-1)\n",
    "    obs = pm.Normal('obs', mu=ar1, sigma=0.1, observed=births_standardized[1:])\n",
    "    trace_ar1 = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "# Model 3: Random Walk Model\n",
    "with pm.Model() as rw_model:\n",
    "    sigma_walk = pm.HalfNormal('sigma_walk', sigma=1.0)\n",
    "    init_dist = pm.Normal.dist(mu=0, sigma=1)\n",
    "    walk = pm.GaussianRandomWalk('walk', mu=0, sigma=sigma_walk, \n",
    "                                init_dist=init_dist, steps=n_obs-1)\n",
    "    sigma_obs = pm.HalfNormal('sigma_obs', sigma=1.0)\n",
    "    obs = pm.Normal('obs', mu=walk, sigma=sigma_obs, observed=births_standardized)\n",
    "    trace_rw = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "print(\"‚úÖ Built three models for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convergence Diagnostics\n",
    "\n",
    "Before interpreting results, we must ensure that MCMC chains have converged to the target distribution.\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "- **R-hat (Gelman-Rubin statistic)**: Should be < 1.01 for convergence\n",
    "- **Effective Sample Size (ESS)**: Should be > 400 for reliable inference\n",
    "- **Monte Carlo Standard Error**: Should be small relative to posterior SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check convergence diagnostics for all models\n",
    "models_traces = {\n",
    "    'Normal Model': trace_normal,\n",
    "    'AR(1) Model': trace_ar1,\n",
    "    'Random Walk': trace_rw\n",
    "}\n",
    "\n",
    "print(\"üîç **Convergence Diagnostics**\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, trace in models_traces.items():\n",
    "    print(f\"\\n**{name}**:\")\n",
    "    summary = az.summary(trace)\n",
    "    \n",
    "    # Check R-hat values\n",
    "    max_rhat = summary['r_hat'].max()\n",
    "    print(f\"   Max R-hat: {max_rhat:.4f} {'‚úÖ' if max_rhat < 1.01 else '‚ùå'}\")\n",
    "    \n",
    "    # Check effective sample size\n",
    "    min_ess = summary['ess_bulk'].min()\n",
    "    print(f\"   Min ESS: {min_ess:.0f} {'‚úÖ' if min_ess > 400 else '‚ùå'}\")\n",
    "    \n",
    "    # Check for divergences\n",
    "    divergences = trace.sample_stats.diverging.sum().values\n",
    "    print(f\"   Divergences: {divergences} {'‚úÖ' if divergences == 0 else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trace plots for convergence assessment\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "# Normal model traces\n",
    "az.plot_trace(trace_normal, var_names=['mu', 'sigma'], axes=axes[0, :])\n",
    "axes[0, 0].set_title('Normal Model - Trace Plots')\n",
    "\n",
    "# AR(1) model traces  \n",
    "az.plot_trace(trace_ar1, var_names=['phi', 'sigma'], axes=axes[1, :])\n",
    "axes[1, 0].set_title('AR(1) Model - Trace Plots')\n",
    "\n",
    "# Random walk model traces\n",
    "az.plot_trace(trace_rw, var_names=['sigma_walk', 'sigma_obs'], axes=axes[2, :])\n",
    "axes[2, 0].set_title('Random Walk Model - Trace Plots')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° **Trace Plot Interpretation**:\")\n",
    "print(\"   ‚Ä¢ **Left panels**: Parameter values over iterations\")\n",
    "print(\"   ‚Ä¢ **Right panels**: Marginal posterior distributions\")\n",
    "print(\"   ‚Ä¢ **Good mixing**: Chains should overlap and explore the space efficiently\")\n",
    "print(\"   ‚Ä¢ **Convergence**: Multiple chains should converge to same distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Information Criteria for Model Comparison\n",
    "\n",
    "Information criteria help us compare models by balancing fit quality with model complexity.\n",
    "\n",
    "### WAIC vs LOO\n",
    "\n",
    "- **WAIC (Widely Applicable Information Criterion)**: Approximates leave-one-out cross-validation\n",
    "- **LOO (Leave-One-Out Cross-Validation)**: More robust but computationally intensive\n",
    "- **Lower values indicate better models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison using information criteria\n",
    "print(\"üìä **Model Comparison using Information Criteria**\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute WAIC and LOO for all models\n",
    "comparison_waic = az.compare(models_traces, ic='waic')\n",
    "comparison_loo = az.compare(models_traces, ic='loo')\n",
    "\n",
    "print(\"\\n**WAIC Comparison**:\")\n",
    "print(comparison_waic)\n",
    "\n",
    "print(\"\\n**LOO Comparison**:\")\n",
    "print(comparison_loo)\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "az.plot_compare(comparison_waic, ax=ax1)\n",
    "ax1.set_title('Model Comparison: WAIC')\n",
    "\n",
    "az.plot_compare(comparison_loo, ax=ax2)\n",
    "ax2.set_title('Model Comparison: LOO')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° **Interpretation**:\")\n",
    "print(\"   ‚Ä¢ **Rank**: Lower rank = better model\")\n",
    "print(\"   ‚Ä¢ **dWAIC/dLOO**: Difference from best model\")\n",
    "print(\"   ‚Ä¢ **Weight**: Relative model probability\")\n",
    "print(\"   ‚Ä¢ **SE**: Standard error of the difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Posterior Predictive Checks\n",
    "\n",
    "Posterior predictive checks help us assess whether our models can reproduce key features of the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive checks for model validation\n",
    "print(\"üîç **Posterior Predictive Checks**\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Generate posterior predictive samples\n",
    "with normal_model:\n",
    "    ppc_normal = pm.sample_posterior_predictive(trace_normal, random_seed=RANDOM_SEED)\n",
    "\n",
    "with ar1_model:\n",
    "    ppc_ar1 = pm.sample_posterior_predictive(trace_ar1, random_seed=RANDOM_SEED)\n",
    "\n",
    "with rw_model:\n",
    "    ppc_rw = pm.sample_posterior_predictive(trace_rw, random_seed=RANDOM_SEED)\n",
    "\n",
    "# Plot posterior predictive checks\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Normal model PPC\n",
    "az.plot_ppc(ppc_normal, num_pp_samples=50, ax=axes[0])\n",
    "axes[0].set_title('Normal Model - PPC')\n",
    "\n",
    "# AR(1) model PPC\n",
    "az.plot_ppc(ppc_ar1, num_pp_samples=50, ax=axes[1])\n",
    "axes[1].set_title('AR(1) Model - PPC')\n",
    "\n",
    "# Random walk model PPC\n",
    "az.plot_ppc(ppc_rw, num_pp_samples=50, ax=axes[2])\n",
    "axes[2].set_title('Random Walk Model - PPC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° **PPC Interpretation**:\")\n",
    "print(\"   ‚Ä¢ **Blue line**: Observed data distribution\")\n",
    "print(\"   ‚Ä¢ **Light blue**: Posterior predictive samples\")\n",
    "print(\"   ‚Ä¢ **Good fit**: Observed data should be typical of predictive samples\")\n",
    "print(\"   ‚Ä¢ **Poor fit**: Systematic deviations indicate model misspecification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series-Specific Diagnostics\n",
    "\n",
    "Time series models require additional diagnostics to check for temporal patterns in residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series specific diagnostics\n",
    "print(\"üìà **Time Series-Specific Diagnostics**\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Function to compute residuals\n",
    "def compute_residuals(observed, predicted_samples):\n",
    "    \"\"\"Compute residuals from posterior predictive samples\"\"\"\n",
    "    pred_mean = predicted_samples.mean(axis=0)\n",
    "    return observed - pred_mean\n",
    "\n",
    "# Compute residuals for each model\n",
    "residuals_normal = compute_residuals(births_standardized, \n",
    "                                   ppc_normal.posterior_predictive['obs'].values.reshape(-1, n_obs))\n",
    "residuals_ar1 = compute_residuals(births_standardized[1:], \n",
    "                                ppc_ar1.posterior_predictive['obs'].values.reshape(-1, n_obs-1))\n",
    "residuals_rw = compute_residuals(births_standardized, \n",
    "                               ppc_rw.posterior_predictive['obs'].values.reshape(-1, n_obs))\n",
    "\n",
    "# Plot residual diagnostics\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "\n",
    "models_residuals = [\n",
    "    ('Normal Model', residuals_normal),\n",
    "    ('AR(1) Model', residuals_ar1),\n",
    "    ('Random Walk', residuals_rw)\n",
    "]\n",
    "\n",
    "for i, (name, residuals) in enumerate(models_residuals):\n",
    "    # Time series plot of residuals\n",
    "    axes[i, 0].plot(residuals, 'o-', alpha=0.7)\n",
    "    axes[i, 0].axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "    axes[i, 0].set_title(f'{name} - Residuals vs Time')\n",
    "    axes[i, 0].set_ylabel('Residuals')\n",
    "    axes[i, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q plot for normality check\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'{name} - Q-Q Plot')\n",
    "    axes[i, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute autocorrelation of residuals\n",
    "print(\"\\n**Residual Autocorrelation (Lag 1)**:\")\n",
    "for name, residuals in models_residuals:\n",
    "    if len(residuals) > 1:\n",
    "        autocorr = np.corrcoef(residuals[:-1], residuals[1:])[0, 1]\n",
    "        print(f\"   {name}: {autocorr:.4f} {'‚úÖ' if abs(autocorr) < 0.1 else '‚ùå'}\")\n",
    "\n",
    "print(\"\\nüí° **Residual Diagnostics Interpretation**:\")\n",
    "print(\"   ‚Ä¢ **Time plot**: Should show no patterns or trends\")\n",
    "print(\"   ‚Ä¢ **Q-Q plot**: Points should follow diagonal line for normality\")\n",
    "print(\"   ‚Ä¢ **Autocorrelation**: Should be close to zero for good models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "### Model Diagnostic Checklist\n",
    "\n",
    "‚úÖ **Convergence**:\n",
    "- R-hat < 1.01 for all parameters\n",
    "- ESS > 400 for reliable inference\n",
    "- No divergent transitions\n",
    "\n",
    "‚úÖ **Model Fit**:\n",
    "- Posterior predictive checks show good agreement\n",
    "- Residuals show no systematic patterns\n",
    "- Information criteria favor your model\n",
    "\n",
    "‚úÖ **Time Series Specific**:\n",
    "- Residuals show no autocorrelation\n",
    "- No obvious temporal patterns in residuals\n",
    "- Model captures key data features (trend, seasonality)\n",
    "\n",
    "### When Models Fail Diagnostics\n",
    "\n",
    "- **Poor convergence**: Increase tune/draws, reparameterize, or use different sampler\n",
    "- **Bad fit**: Add missing components (trend, seasonality, AR terms)\n",
    "- **Residual patterns**: Consider more complex models or different distributions\n",
    "\n",
    "**Next**: In Section 6, we'll use our validated models for forecasting and practical applications.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**:\n",
    "- Always check convergence before interpreting results\n",
    "- Use multiple criteria for model comparison\n",
    "- Posterior predictive checks are essential for validation\n",
    "- Time series models require specialized residual diagnostics\n",
    "- Iterate and improve models based on diagnostic results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
