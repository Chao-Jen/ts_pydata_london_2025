{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Advanced Models\n",
    "\n",
    "#### PyData London 2025 - Bayesian Time Series Analysis with PyMC\n",
    "\n",
    "---\n",
    "\n",
    "## State-Space Models\n",
    "\n",
    "State-space models are powerful frameworks for time series analysis that separate the **latent state** (unobserved) from the **observations** (observed). This separation allows us to:\n",
    "\n",
    "- Model complex dynamics in the latent space\n",
    "- Handle missing observations naturally\n",
    "- Incorporate measurement error\n",
    "- Build hierarchical time series models\n",
    "\n",
    "### Mathematical Framework\n",
    "\n",
    "**State equation**: $x_t = f(x_{t-1}, \\theta) + \\eta_t$\n",
    "\n",
    "**Observation equation**: $y_t = g(x_t, \\phi) + \\epsilon_t$\n",
    "\n",
    "Where:\n",
    "- $x_t$ is the latent state\n",
    "- $y_t$ is the observation\n",
    "- $\\eta_t, \\epsilon_t$ are noise terms\n",
    "- $\\theta, \\phi$ are parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Section 4\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import arviz as az\n",
    "import warnings\n",
    "\n",
    "# Configure plotting and suppress warnings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"🔧 Section 4 libraries loaded successfully!\")\n",
    "print(\"Ready to build advanced Bayesian time series models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Local Level Model (State-Space)\n",
    "\n",
    "The local level model is the simplest state-space model, where the latent state follows a random walk and observations are noisy measurements of this state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "births_data = pl.read_csv('../data/births.csv', null_values=['null', 'NA', '', 'NULL'])\n",
    "births_data = births_data.filter(pl.col('day').is_not_null())\n",
    "\n",
    "monthly_births = (births_data\n",
    "    .group_by(['year', 'month'])\n",
    "    .agg(pl.col('births').sum())\n",
    "    .sort(['year', 'month'])\n",
    ")\n",
    "\n",
    "births_subset = (monthly_births\n",
    "    .filter((pl.col('year') >= 1970) & (pl.col('year') <= 1990))\n",
    "    .with_row_index('index')\n",
    ")\n",
    "\n",
    "original_data = births_subset['births'].to_numpy()\n",
    "births_standardized = (original_data - original_data.mean()) / original_data.std()\n",
    "n_obs = len(births_standardized)\n",
    "\n",
    "print(f\"📊 Data prepared: {n_obs} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Local Level Model (State-Space)\n",
    "with pm.Model() as local_level_model:\n",
    "    # Process noise (state evolution)\n",
    "    sigma_level = pm.HalfNormal('sigma_level', sigma=0.5)\n",
    "    \n",
    "    # Observation noise\n",
    "    sigma_obs = pm.HalfNormal('sigma_obs', sigma=0.5)\n",
    "    \n",
    "    # Initial level\n",
    "    init_level = pm.Normal('init_level', mu=0, sigma=1)\n",
    "    \n",
    "    # Level process (latent state - random walk)\n",
    "    init_dist = pm.Normal.dist(mu=init_level, sigma=sigma_level)\n",
    "    level = pm.GaussianRandomWalk('level',\n",
    "                                 mu=0,\n",
    "                                 sigma=sigma_level,\n",
    "                                 init_dist=init_dist,\n",
    "                                 steps=n_obs-1)\n",
    "    \n",
    "    # Observations (noisy measurements of latent state)\n",
    "    obs = pm.Normal('obs', mu=level, sigma=sigma_obs, observed=births_standardized)\n",
    "\n",
    "# Sample from local level model\n",
    "with local_level_model:\n",
    "    trace_local_level = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "print(\"Local Level Model Summary:\")\n",
    "print(az.summary(trace_local_level, var_names=['sigma_level', 'sigma_obs', 'init_level']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Stochastic Volatility Model\n",
    "\n",
    "Stochastic volatility models are essential for financial time series where the variance itself changes over time. These models assume that volatility follows its own stochastic process.\n",
    "\n",
    "### Model Specification\n",
    "\n",
    "**Returns equation**: $r_t = \\mu + \\sigma_t \\epsilon_t$\n",
    "\n",
    "**Volatility equation**: $\\log(\\sigma_t^2) = \\log(\\sigma_{t-1}^2) + \\nu_t$\n",
    "\n",
    "Where $\\epsilon_t, \\nu_t \\sim \\mathcal{N}(0,1)$ are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic financial returns for stochastic volatility demo\n",
    "np.random.seed(42)\n",
    "n_periods = 200\n",
    "true_mu = 0.02\n",
    "true_tau = 0.1\n",
    "\n",
    "# Simulate log-volatility as random walk\n",
    "log_vol = np.cumsum(np.random.normal(0, true_tau, n_periods))\n",
    "vol = np.exp(log_vol / 2)\n",
    "\n",
    "# Simulate returns\n",
    "returns = np.random.normal(true_mu, vol)\n",
    "\n",
    "print(f\"📈 Generated {n_periods} synthetic returns\")\n",
    "print(f\"   Mean return: {returns.mean():.4f}\")\n",
    "print(f\"   Return volatility: {returns.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Stochastic Volatility Model\n",
    "with pm.Model() as stoch_vol_model:\n",
    "    # Mean return\n",
    "    mu = pm.Normal('mu', mu=0, sigma=0.1)\n",
    "    \n",
    "    # Volatility process parameters\n",
    "    tau = pm.HalfNormal('tau', sigma=0.2)  # Innovation in log-volatility\n",
    "    \n",
    "    # Log-volatility random walk\n",
    "    init_dist = pm.Normal.dist(mu=np.log(0.1), sigma=1)\n",
    "    log_sigma = pm.GaussianRandomWalk('log_sigma',\n",
    "                                     mu=0,\n",
    "                                     sigma=tau,\n",
    "                                     init_dist=init_dist,\n",
    "                                     steps=n_periods-1)\n",
    "    \n",
    "    # Convert to volatility\n",
    "    sigma = pm.Deterministic('sigma', pm.math.exp(log_sigma))\n",
    "    \n",
    "    # Likelihood\n",
    "    y_pred = pm.Normal('y_pred', mu=mu, sigma=sigma, observed=returns)\n",
    "\n",
    "# Sample from stochastic volatility model\n",
    "with stoch_vol_model:\n",
    "    trace_sv = pm.sample(1000, tune=2000, target_accept=0.9, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "print(\"Stochastic Volatility Model Summary:\")\n",
    "print(az.summary(trace_sv, var_names=['mu', 'tau']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Gaussian Process Regression\n",
    "\n",
    "Gaussian Processes (GPs) provide a non-parametric approach to time series modeling. They're particularly useful when:\n",
    "- The functional form is unknown\n",
    "- You want to capture complex, non-linear patterns\n",
    "- Uncertainty quantification is crucial\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Covariance function**: Defines the relationship between points\n",
    "- **Length scale**: Controls how quickly correlations decay\n",
    "- **Marginal variance**: Controls the overall variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for GP regression\n",
    "# Use a subset for computational efficiency\n",
    "n_gp = 100\n",
    "X_gp = np.arange(n_gp)[:, None]  # Time points (must be 2D for GP)\n",
    "y_gp = births_standardized[:n_gp]  # Observations\n",
    "\n",
    "print(f\"📊 GP data: {n_gp} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Gaussian Process Regression\n",
    "with pm.Model() as gp_model:\n",
    "    # GP hyperparameters\n",
    "    length_scale = pm.HalfNormal('length_scale', sigma=2.0)\n",
    "    eta = pm.HalfNormal('eta', sigma=1.0)  # marginal standard deviation\n",
    "    \n",
    "    # Define the covariance function (RBF/Squared Exponential)\n",
    "    cov_func = eta**2 * pm.gp.cov.ExpQuad(1, ls=length_scale)\n",
    "    \n",
    "    # GP prior\n",
    "    gp = pm.gp.Marginal(cov_func=cov_func)\n",
    "    \n",
    "    # Observation noise\n",
    "    sigma_gp = pm.HalfNormal('sigma_gp', sigma=0.5)\n",
    "    \n",
    "    # Observed data\n",
    "    y_pred = gp.marginal_likelihood('y_pred', X=X_gp, y=y_gp, sigma=sigma_gp)\n",
    "\n",
    "# Sample from the model\n",
    "with gp_model:\n",
    "    trace_gp = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "print(\"Gaussian Process Model Summary:\")\n",
    "print(az.summary(trace_gp, var_names=['length_scale', 'eta', 'sigma_gp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Multivariate Time Series\n",
    "\n",
    "Many real-world applications involve multiple related time series. PyMC provides tools for modeling these relationships through multivariate distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic multivariate time series\n",
    "np.random.seed(42)\n",
    "n_series = 3\n",
    "n_time = 100\n",
    "\n",
    "# True correlation matrix\n",
    "true_corr = np.array([[1.0, 0.7, 0.3],\n",
    "                      [0.7, 1.0, 0.5],\n",
    "                      [0.3, 0.5, 1.0]])\n",
    "\n",
    "# Generate correlated innovations\n",
    "innovations = np.random.multivariate_normal(np.zeros(n_series), true_corr, n_time)\n",
    "\n",
    "# Create multivariate random walk\n",
    "mv_series = np.cumsum(innovations, axis=0)\n",
    "\n",
    "print(f\"📊 Generated {n_series} correlated time series with {n_time} observations each\")\n",
    "print(f\"   Empirical correlations:\")\n",
    "print(np.corrcoef(mv_series.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Multivariate Random Walk\n",
    "with pm.Model() as mv_model:\n",
    "    # Innovation covariance matrix\n",
    "    # Use LKJ prior for correlation matrix\n",
    "    corr_matrix = pm.LKJCorr('corr_matrix', n=n_series, eta=2)\n",
    "    \n",
    "    # Standard deviations\n",
    "    sigma_mv = pm.HalfNormal('sigma_mv', sigma=1, shape=n_series)\n",
    "    \n",
    "    # Covariance matrix\n",
    "    cov_matrix = pm.Deterministic('cov_matrix', \n",
    "                                 pt.diag(sigma_mv) @ corr_matrix @ pt.diag(sigma_mv))\n",
    "    \n",
    "    # Multivariate random walk\n",
    "    mv_walk = pm.MvGaussianRandomWalk('mv_walk',\n",
    "                                     mu=np.zeros(n_series),\n",
    "                                     cov=cov_matrix,\n",
    "                                     steps=n_time-1,\n",
    "                                     observed=mv_series[1:])\n",
    "\n",
    "# Sample from multivariate model\n",
    "with mv_model:\n",
    "    trace_mv = pm.sample(1000, tune=1000, random_seed=RANDOM_SEED, chains=2)\n",
    "\n",
    "print(\"Multivariate Model Summary:\")\n",
    "print(az.summary(trace_mv, var_names=['sigma_mv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Insights\n",
    "\n",
    "Let's compare the performance of our advanced models and understand their strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model fits (for models that can be compared)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Local Level Model\n",
    "level_mean = az.extract(trace_local_level)['level'].mean(dim='sample')\n",
    "axes[0,0].plot(births_standardized, 'o-', alpha=0.6, label='Observed')\n",
    "axes[0,0].plot(level_mean, '-', linewidth=2, label='Latent Level')\n",
    "axes[0,0].set_title('Local Level Model')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Stochastic Volatility\n",
    "vol_mean = az.extract(trace_sv)['sigma'].mean(dim='sample')\n",
    "axes[0,1].plot(returns, alpha=0.6, label='Returns')\n",
    "axes[0,1].plot(vol_mean, linewidth=2, label='Estimated Volatility')\n",
    "axes[0,1].set_title('Stochastic Volatility Model')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Gaussian Process (prediction)\n",
    "# Generate predictions for GP\n",
    "with gp_model:\n",
    "    X_new = np.arange(n_gp + 20)[:, None]  # Extend beyond observed data\n",
    "    gp_pred = gp.conditional('gp_pred', X_new)\n",
    "    pred_samples = pm.sample_posterior_predictive(trace_gp, var_names=['gp_pred'], random_seed=RANDOM_SEED)\n",
    "\n",
    "gp_mean = pred_samples.posterior_predictive['gp_pred'].mean(dim=['chain', 'draw'])\n",
    "gp_hdi = az.hdi(pred_samples.posterior_predictive['gp_pred'], hdi_prob=0.9)\n",
    "\n",
    "axes[1,0].plot(y_gp, 'o', alpha=0.6, label='Observed')\n",
    "axes[1,0].plot(gp_mean, '-', linewidth=2, label='GP Mean')\n",
    "axes[1,0].fill_between(range(len(gp_mean)), \n",
    "                      gp_hdi.sel(hdi='lower'), \n",
    "                      gp_hdi.sel(hdi='higher'), \n",
    "                      alpha=0.3, label='90% HDI')\n",
    "axes[1,0].axvline(n_gp, color='red', linestyle='--', alpha=0.7, label='Forecast Start')\n",
    "axes[1,0].set_title('Gaussian Process Regression')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Multivariate Series\n",
    "for i in range(n_series):\n",
    "    axes[1,1].plot(mv_series[:, i], label=f'Series {i+1}')\n",
    "axes[1,1].set_title('Multivariate Time Series')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 **Model Insights**:\")\n",
    "print(\"   • **Local Level**: Separates signal from noise effectively\")\n",
    "print(\"   • **Stochastic Volatility**: Captures time-varying uncertainty\")\n",
    "print(\"   • **Gaussian Process**: Provides flexible, non-parametric fits\")\n",
    "print(\"   • **Multivariate**: Models correlations between series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section, we've explored advanced Bayesian time series models:\n",
    "\n",
    "1. **State-Space Models**: Separate latent dynamics from observations\n",
    "2. **Stochastic Volatility**: Model time-varying uncertainty\n",
    "3. **Gaussian Processes**: Non-parametric, flexible modeling\n",
    "4. **Multivariate Models**: Handle correlated time series\n",
    "\n",
    "### When to Use Each Model\n",
    "\n",
    "- **State-Space**: When you have latent variables or missing data\n",
    "- **Stochastic Volatility**: For financial data with changing variance\n",
    "- **Gaussian Process**: When functional form is unknown\n",
    "- **Multivariate**: For multiple related time series\n",
    "\n",
    "**Next**: In Section 5, we'll learn how to properly evaluate and compare these models.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaways**:\n",
    "- Advanced models provide greater flexibility but require more careful specification\n",
    "- State-space models are powerful for latent variable modeling\n",
    "- Stochastic volatility is essential for financial time series\n",
    "- Gaussian processes offer non-parametric flexibility\n",
    "- Multivariate models capture cross-series dependencies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
